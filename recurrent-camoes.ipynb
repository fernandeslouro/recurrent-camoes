{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"nav_menu":{},"toc":{"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":6,"toc_cell":false,"toc_section_display":"block","toc_window_display":false},"colab":{"name":"recurrent-camoes.ipynb","provenance":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0P5q9gICavdP","colab_type":"text"},"source":["**Chapter 16 – Natural Language Processing with RNNs and Attention**"]},{"cell_type":"markdown","metadata":{"id":"E5-YxMNBavdd","colab_type":"text"},"source":["_This notebook contains all the sample code in chapter 16._"]},{"cell_type":"markdown","metadata":{"id":"GmcSt3TFavdn","colab_type":"text"},"source":["<table align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/16_nlp_with_rnns_and_attention.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","</table>"]},{"cell_type":"code","metadata":{"id":"26ZBmNUI9s-R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"error","timestamp":1592392132349,"user_tz":-60,"elapsed":1442,"user":{"displayName":"João Louro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM2RkCUqPA0xRPBwn8sRPRg2h5H-7x8rxPCXxcTQ=s64","userId":"04379741539671219878"}},"outputId":"4f5307a6-89d3-431a-c75b-47c8f111e011"},"source":["import subprocess, shlex\n","s = subprocess.Popen(shlex.split(\n","    f'jupyter nbconvert \"{n.as_posix()}\" --to pdf --output \"{n.stem.replace(\" \", \"_\")}\"'\n","    ), shell = False, stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n","s.wait()\n","s.stdout.read()"],"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-a5857817794b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshlex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m s = subprocess.Popen(shlex.split(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34mf'jupyter nbconvert \"{n.as_posix()}\" --to pdf --output \"{n.stem.replace(\" \", \"_\")}\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     ), shell = False, stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n\u001b[1;32m      5\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"rSy-m0jdavd5","colab_type":"text"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"Dx4ZVP4QaveC","colab_type":"text"},"source":["First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."]},{"cell_type":"code","metadata":{"id":"nowe0G2raveK","colab_type":"code","colab":{}},"source":["# Python ≥3.5 is required\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# Scikit-Learn ≥0.20 is required\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","try:\n","    # %tensorflow_version only exists in Colab.\n","    %tensorflow_version 2.x\n","    !pip install -q -U tensorflow-addons\n","    IS_COLAB = True\n","except Exception:\n","    IS_COLAB = False\n","\n","# TensorFlow ≥2.0 is required\n","import tensorflow as tf\n","from tensorflow import keras\n","assert tf.__version__ >= \"2.0\"\n","\n","if not tf.config.list_physical_devices('GPU'):\n","    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n","    if IS_COLAB:\n","        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n","\n","# Common imports\n","import numpy as np\n","import os\n","\n","# to make this notebook's output stable across runs\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# To plot pretty figures\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","\n","# Where to save the figures\n","PROJECT_ROOT_DIR = \".\"\n","CHAPTER_ID = \"nlp\"\n","IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n","os.makedirs(IMAGES_PATH, exist_ok=True)\n","\n","def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n","    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n","    print(\"Saving figure\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, format=fig_extension, dpi=resolution)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0yr6c6bMavfO","colab_type":"text"},"source":["# Char-RNN"]},{"cell_type":"markdown","metadata":{"id":"AcqkqwPjavfU","colab_type":"text"},"source":["## Splitting a sequence into batches of shuffled windows"]},{"cell_type":"markdown","metadata":{"id":"YMeQ0OU-avfZ","colab_type":"text"},"source":["For example, let's split the sequence 0 to 14 into windows of length 5, each shifted by 2 (e.g.,`[0, 1, 2, 3, 4]`, `[2, 3, 4, 5, 6]`, etc.), then shuffle them, and split them into inputs (the first 4 steps) and targets (the last 4 steps) (e.g., `[2, 3, 4, 5, 6]` would be split into `[[2, 3, 4, 5], [3, 4, 5, 6]]`), then create batches of 3 such input/target pairs:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"KzjVzRIzavfh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"ok","timestamp":1591551474262,"user_tz":-60,"elapsed":19486,"user":{"displayName":"João Louro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM2RkCUqPA0xRPBwn8sRPRg2h5H-7x8rxPCXxcTQ=s64","userId":"04379741539671219878"}},"outputId":"4567483b-059d-48f6-dd13-28a8b581a080"},"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","n_steps = 5\n","dataset = tf.data.Dataset.from_tensor_slices(tf.range(15))\n","dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n","dataset = dataset.flat_map(lambda window: window.batch(n_steps))\n","dataset = dataset.shuffle(10).map(lambda window: (window[:-1], window[1:]))\n","dataset = dataset.batch(3).prefetch(1)\n","for index, (X_batch, Y_batch) in enumerate(dataset):\n","    print(\"_\" * 20, \"Batch\", index, \"\\nX_batch\")\n","    print(X_batch.numpy())\n","    print(\"=\" * 5, \"\\nY_batch\")\n","    print(Y_batch.numpy())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["____________________ Batch 0 \n","X_batch\n","[[6 7 8 9]\n"," [2 3 4 5]\n"," [4 5 6 7]]\n","===== \n","Y_batch\n","[[ 7  8  9 10]\n"," [ 3  4  5  6]\n"," [ 5  6  7  8]]\n","____________________ Batch 1 \n","X_batch\n","[[ 0  1  2  3]\n"," [ 8  9 10 11]\n"," [10 11 12 13]]\n","===== \n","Y_batch\n","[[ 1  2  3  4]\n"," [ 9 10 11 12]\n"," [11 12 13 14]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1QQdLZR5avgC","colab_type":"text"},"source":["## Loading the Data and Preparing the Dataset"]},{"cell_type":"code","metadata":{"id":"Gu_93sclavgJ","colab_type":"code","colab":{}},"source":["shakespeare_url = \"https://raw.githubusercontent.com/fernandeslouro/recurrent-camoes/master/lusiadas.txt\"\n","filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n","with open(filepath) as f:\n","    shakespeare_text = f.read()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlKA2lzSavgo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"ok","timestamp":1591551474299,"user_tz":-60,"elapsed":18980,"user":{"displayName":"João Louro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM2RkCUqPA0xRPBwn8sRPRg2h5H-7x8rxPCXxcTQ=s64","userId":"04379741539671219878"}},"outputId":"e6e8b7ff-989a-4113-c7b7-5218c3a76604"},"source":["print(shakespeare_text[:148])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","As armas e os barões assinalados,\n","Que da ocidental praia Lusitana,\n","Por mares nunca de antes navegados,\n","Passaram ainda além da Taprobana,\n","Em perigo\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0_dur3qUavhL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591551474306,"user_tz":-60,"elapsed":18834,"user":{"displayName":"João Louro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM2RkCUqPA0xRPBwn8sRPRg2h5H-7x8rxPCXxcTQ=s64","userId":"04379741539671219878"}},"outputId":"092f03aa-14f2-45ea-e372-ea3fee3fdcbf"},"source":["\"\".join(sorted(set(shakespeare_text.lower())))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n !\"\\'(),-.:;?[]abcdefghijlmnopqrstuvxyzàáâãçèéêíòóôõúü'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Yr-AgiQIavho","colab_type":"code","colab":{}},"source":["tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n","tokenizer.fit_on_texts(shakespeare_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qOQYEnyRavh-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591551474316,"user_tz":-60,"elapsed":18517,"user":{"displayName":"João Louro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM2RkCUqPA0xRPBwn8sRPRg2h5H-7x8rxPCXxcTQ=s64","userId":"04379741539671219878"}},"outputId":"4a297ddb-db5f-4e0a-9c91-4e587d2ea06a"},"source":["tokenizer.texts_to_sequences([\"First\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[21, 8, 6, 5, 10]]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"yUeQNQc7aviZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591551474414,"user_tz":-60,"elapsed":18448,"user":{"displayName":"João Louro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM2RkCUqPA0xRPBwn8sRPRg2h5H-7x8rxPCXxcTQ=s64","userId":"04379741539671219878"}},"outputId":"290d0bb7-538c-4a53-d463-feaa46770894"},"source":["tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['g r d i a']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"SDBgxvsLavi8","colab_type":"code","colab":{}},"source":["max_id = len(tokenizer.word_index) # number of distinct characters\n","dataset_size = tokenizer.document_count # total number of characters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KYqO8Jn1avjV","colab_type":"code","colab":{}},"source":["[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n","train_size = dataset_size * 90 // 100\n","dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pfIRmqhdavj0","colab_type":"code","colab":{}},"source":["n_steps = 100\n","window_length = n_steps + 1 # target = input shifted 1 character ahead\n","dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdBZcbj7avkW","colab_type":"code","colab":{}},"source":["dataset = dataset.flat_map(lambda window: window.batch(window_length))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0x4ojMFjavkq","colab_type":"code","colab":{}},"source":["np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALIoqsqqavlD","colab_type":"code","colab":{}},"source":["batch_size = 32\n","dataset = dataset.shuffle(10000).batch(batch_size)\n","dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pCs1aVZIavla","colab_type":"code","colab":{}},"source":["dataset = dataset.map(\n","    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6mZuCEcavlt","colab_type":"code","colab":{}},"source":["dataset = dataset.prefetch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9B8Y5Xk0avmA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591551478963,"user_tz":-60,"elapsed":22273,"user":{"displayName":"João Louro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM2RkCUqPA0xRPBwn8sRPRg2h5H-7x8rxPCXxcTQ=s64","userId":"04379741539671219878"}},"outputId":"dd43d44b-8ec1-49ac-8b7e-002913e1b28a"},"source":["for X_batch, Y_batch in dataset.take(1):\n","    print(X_batch.shape, Y_batch.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(32, 100, 54) (32, 100)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pgijBqVkavmW","colab_type":"text"},"source":["## Creating and Training the Model"]},{"cell_type":"code","metadata":{"id":"YTGA7X7mavmb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":184},"executionInfo":{"status":"error","timestamp":1591392209285,"user_tz":-60,"elapsed":15418726,"user":{"displayName":"João Louro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhM2RkCUqPA0xRPBwn8sRPRg2h5H-7x8rxPCXxcTQ=s64","userId":"04379741539671219878"}},"outputId":"3852ef04-f466-45dd-b94e-73f87dcc9340"},"source":["model = keras.models.Sequential([\n","    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n","                     dropout=0.2, recurrent_dropout=0.2),\n","    keras.layers.GRU(128, return_sequences=True,\n","                     dropout=0.2, recurrent_dropout=0.2),\n","    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n","                                                    activation=\"softmax\"))\n","])\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n","history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n","                    epochs=6)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/6\n","8882/8882 [==============================] - 10128s 1s/step - loss: 1.6713\n","Epoch 2/6\n","8882/8882 [==============================] - 9648s 1s/step - loss: 1.4681\n","Epoch 3/6\n","5523/8882 [=================>............] - ETA: 1:01:48 - loss: 1.4208"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"69TAkqbNNoX2","colab_type":"code","colab":{}},"source":["model.save('char_rnn') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MtEOM0wKavmv","colab_type":"text"},"source":["\n","## Using the Model to Generate Text\n"]},{"cell_type":"code","metadata":{"id":"A5q4G-zeavmz","colab_type":"code","colab":{}},"source":["def preprocess(texts):\n","    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n","    return tf.one_hot(X, max_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuLNExzTavnI","colab_type":"code","colab":{}},"source":["X_new = preprocess([\"Os mar\"])\n","Y_pred = model.predict_classes(X_new)\n","tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3WcYeTbavnd","colab_type":"code","colab":{}},"source":["tf.random.set_seed(42)\n","\n","tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5ZAKp_gavn2","colab_type":"code","colab":{}},"source":["def next_char(text, temperature=1):\n","    X_new = preprocess([text])\n","    y_proba = model.predict(X_new)[0, -1:, :]\n","    rescaled_logits = tf.math.log(y_proba) / temperature\n","    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n","    return tokenizer.sequences_to_texts(char_id.numpy())[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-hfHcLhavoI","colab_type":"code","colab":{}},"source":["tf.random.set_seed(42)\n","\n","next_char(\"Os mar\", temperature=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnkH2wvAavod","colab_type":"code","colab":{}},"source":["def complete_text(text, n_chars=50, temperature=1):\n","    for _ in range(n_chars):\n","        text += next_char(text, temperature)\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o1jqvNthavow","colab_type":"code","colab":{}},"source":["tf.random.set_seed(42)\n","\n","print(complete_text(\"t\", temperature=0.2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RPGndG3savpC","colab_type":"code","colab":{}},"source":["print(complete_text(\"t\", temperature=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrY3Mw97avpX","colab_type":"code","colab":{}},"source":["print(complete_text(\"t\", temperature=0.5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4hJ3GZp4avpo","colab_type":"text"},"source":["## Stateful RNN"]},{"cell_type":"code","metadata":{"id":"uDjVzTq-avpr","colab_type":"code","colab":{}},"source":["tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXvunlJxavp7","colab_type":"code","colab":{}},"source":["dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n","dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n","dataset = dataset.flat_map(lambda window: window.batch(window_length))\n","dataset = dataset.repeat().batch(1)\n","dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n","dataset = dataset.map(\n","    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n","dataset = dataset.prefetch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"msH36vuLavqQ","colab_type":"code","colab":{}},"source":["batch_size = 32\n","encoded_parts = np.array_split(encoded[:train_size], batch_size)\n","datasets = []\n","for encoded_part in encoded_parts:\n","    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n","    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n","    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n","    datasets.append(dataset)\n","dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n","dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n","dataset = dataset.map(\n","    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n","dataset = dataset.prefetch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCSBdRuOavqf","colab_type":"code","colab":{}},"source":["model = keras.models.Sequential([\n","    keras.layers.GRU(128, return_sequences=True, stateful=True,\n","                     dropout=0.2, recurrent_dropout=0.2,\n","                     batch_input_shape=[batch_size, None, max_id]),\n","    keras.layers.GRU(128, return_sequences=True, stateful=True,\n","                     dropout=0.2, recurrent_dropout=0.2),\n","    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n","                                                    activation=\"softmax\"))\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lRcXokEZavqu","colab_type":"code","colab":{}},"source":["class ResetStatesCallback(keras.callbacks.Callback):\n","    def on_epoch_begin(self, epoch, logs):\n","        self.model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0P2nCH1Favq_","colab_type":"code","colab":{}},"source":["model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n","steps_per_epoch = train_size // batch_size // n_steps\n","history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=500,\n","                    callbacks=[ResetStatesCallback()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8v7pM7F0avrf","colab_type":"text"},"source":["To use the model with different batch sizes, we need to create a stateless copy. We can get rid of dropout since it is only used during training:"]},{"cell_type":"code","metadata":{"id":"NNjGK45_avrk","colab_type":"code","colab":{}},"source":["stateless_model = keras.models.Sequential([\n","    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n","    keras.layers.GRU(128, return_sequences=True),\n","    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n","                                                    activation=\"softmax\"))\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SQkxAHGsavr3","colab_type":"text"},"source":["To set the weights, we first need to build the model (so the weights get created):"]},{"cell_type":"code","metadata":{"id":"FHU0x0IIavr7","colab_type":"code","colab":{}},"source":["stateless_model.build(tf.TensorShape([None, None, max_id]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zo3fbSuhavsM","colab_type":"code","colab":{}},"source":["stateless_model.set_weights(model.get_weights())\n","model = stateless_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpBx2VTmavsb","colab_type":"code","colab":{}},"source":["tf.random.set_seed(42)\n","\n","print(complete_text(\"t\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OINFOxIfvfC5","colab_type":"code","colab":{}},"source":["print(complete_text('A', n_chars=2000, temperature=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amuuCSycvw6l","colab_type":"code","colab":{}},"source":["print(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aW8TJnUEv616","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}